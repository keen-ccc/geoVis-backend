{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cityname  zone     name                address  price         lon  \\\n",
      "0  阿坝藏族羌族自治州    茂县     晋茂新园     四川省阿坝藏族羌族自治州茂县晋茂新园   5001  103.840876   \n",
      "1  阿坝藏族羌族自治州  马尔康市   嘉绒锦绣尚城          四川省德阳市罗江区锦绣尚城   7178  104.505571   \n",
      "2  阿坝藏族羌族自治州  马尔康市     政法大楼   四川省阿坝藏族羌族自治州马尔康市政法大楼   9008  102.216011   \n",
      "3  阿坝藏族羌族自治州  马尔康市     绒兴家苑   四川省阿坝藏族羌族自治州马尔康市绒兴家苑   5879  102.220008   \n",
      "4        巴中市   巴州区  兴合·半山逸城  四川省巴中市巴州区兴合·半山逸城(公交站)   5297  106.749067   \n",
      "\n",
      "         lat  \n",
      "0  31.666803  \n",
      "1  31.306334  \n",
      "2  31.902818  \n",
      "3  31.900094  \n",
      "4  31.869288  \n"
     ]
    }
   ],
   "source": [
    "# 将utf-8转换成utf-8-sig\n",
    "price_data = pd.read_csv('allPrice.csv')\n",
    "print(price_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_data = pd.read_csv('allPrice.csv')\n",
    "grid = gpd.read_file('grids.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cal_max_min_houseprice(grid, data,house_price):\n",
    "    print(\"计算price最大最小值\")\n",
    "    print(grid.columns)\n",
    "    # 为网格数据建立空间索引\n",
    "    grid = grid.set_geometry('geometry')\n",
    "    print(grid.columns)\n",
    "    grid.sindex  # 创建空间索引\n",
    "    print(grid.sindex)\n",
    "    # 将数据转换为GeoDataFrame\n",
    "    data_gdf = gpd.GeoDataFrame(data, geometry=[Point(xy) for xy in zip(data['lon'], data['lat'])])\n",
    "    data_gdf.crs = grid.crs  # 确保坐标参考系一致\n",
    "\n",
    "    # 明确指定几何列\n",
    "    data_gdf = data_gdf.set_geometry('geometry')\n",
    "\n",
    "    # 遍历网格，使用空间索引进行筛选\n",
    "    for i, row in grid.iterrows():\n",
    "        # 获取当前网格的几何边界\n",
    "        grid_polygon = row['geometry']\n",
    "\n",
    "        # # 打印网格的边界信息，调试用\n",
    "        # print(f\"处理第 {i} 个网格，边界：\", grid_polygon.bounds)\n",
    "\n",
    "        # 使用空间索引查找可能在当前网格内的点\n",
    "        possible_matches_index = list(data_gdf.sindex.intersection(grid_polygon.bounds))\n",
    "        # print(f\"可能的匹配项索引：{possible_matches_index}\")\n",
    "        \n",
    "        # 提取这些候选数据\n",
    "        possible_matches = data_gdf.iloc[possible_matches_index]\n",
    "        # print(\"possible matches:\",possible_matches)\n",
    "\n",
    "        # 筛选在当前网格内的点\n",
    "        filtered_data = possible_matches[possible_matches.geometry.within(grid_polygon)]\n",
    "\n",
    "        if not filtered_data.empty:\n",
    "            # 计算人口密度的平均值\n",
    "            mean_value = np.mean(filtered_data['price'])\n",
    "            house_price.append(mean_value)\n",
    "        else:\n",
    "            house_price.append(0)\n",
    "        \n",
    "        if i % 100000 == 0:\n",
    "            print(f\"已完成 {i} 个网格\")\n",
    "    \n",
    "    return house_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算price最大最小值\n",
      "Index(['geometry'], dtype='object')\n",
      "Index(['geometry'], dtype='object')\n",
      "<geopandas.sindex.SpatialIndex object at 0x000002D2F83E2640>\n",
      "已完成 0 个网格\n",
      "已完成 100000 个网格\n",
      "已完成 200000 个网格\n",
      "已完成 300000 个网格\n",
      "已完成 400000 个网格\n",
      "已完成 500000 个网格\n",
      "已完成 600000 个网格\n",
      "已完成 700000 个网格\n",
      "已完成 800000 个网格\n",
      "已完成 900000 个网格\n",
      "房价最大值： 55852.333333333336\n",
      "房价最小值： 0\n"
     ]
    }
   ],
   "source": [
    "house_price = []\n",
    "\n",
    "house_price = cal_max_min_houseprice(grid, house_data, house_price)\n",
    "# 去除NaN值后计算最大最小值\n",
    "# house_price = [x for x in house_price if not np.isnan(x)]\n",
    "# print(population_density)\n",
    "print(\"房价最大值：\",max(house_price))#55852.333333333336\n",
    "print(\"房价最小值：\",min(house_price))#0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "989000\n"
     ]
    }
   ],
   "source": [
    "print(len(house_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('house_price.npy', house_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-max标准化\n",
    "def min_max_scaler(data):\n",
    "    data = (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_house_price = min_max_scaler(house_price)\n",
    "# 保存到文件\n",
    "np.save('scale_house_price.npy',scale_house_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02407885 0.0299892  0.05226548 0.04780402 0.04329912 0.01357053\n",
      " 0.02278509 0.02757853 0.09408158 0.04624654]\n"
     ]
    }
   ],
   "source": [
    "loaded_scale_house_price = np.load('scale_house_price.npy')\n",
    "print(loaded_scale_house_price[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3120\n"
     ]
    }
   ],
   "source": [
    "print(len(scale_house_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_price_prob = []\n",
    "sum_house_price = np.sum(scale_house_price)\n",
    "# 计算概率矩阵\n",
    "for i in range(len(scale_house_price)):\n",
    "    house_price_prob.append(scale_house_price[i] / sum_house_price)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "989000\n"
     ]
    }
   ],
   "source": [
    "print(len(house_price_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('prob_house_price.npy',house_price_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 定义文件路径\n",
    "path = \"D:\\\\系统默认\\\\桌面\\\\邮政\\\\数据调研\\\\newPrice\"\n",
    "\n",
    "# 初始化一个空的 DataFrame\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# 遍历所有文件\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(path, file)\n",
    "        try:\n",
    "            # 尝试使用 utf-8 编码读取 CSV 文件\n",
    "            df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            # 如果失败，尝试使用 latin1 编码读取 CSV 文件\n",
    "            df = pd.read_csv(file_path, encoding='latin1')\n",
    "        # 将数据追加到 combined_df\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "# 保存合并后的数据到新的 CSV 文件，使用带有 BOM 的 UTF-8 编码\n",
    "combined_df.to_csv('combined_data.csv', encoding='utf-8-sig', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 定义文件路径\n",
    "path = \"D:\\\\系统默认\\\\桌面\\\\邮政\\\\数据调研\\\\Price\"\n",
    "\n",
    "# 初始化一个空的 DataFrame\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# 遍历所有文件\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(path, file)\n",
    "        # 读取 CSV 文件\n",
    "        df = pd.read_csv(file_path)\n",
    "        # 将数据追加到 combined_df\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "# 保存合并后的数据到新的 CSV 文件，使用带有 BOM 的 UTF-8 编码\n",
    "combined_df.to_csv('combined_data.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 定义文件路径\n",
    "path = \"D:\\\\系统默认\\\\桌面\\\\邮政\\\\数据调研\\\\Price\"\n",
    "\n",
    "# 初始化一个空的 DataFrame\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# 遍历所有文件\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(path, file)\n",
    "        # 读取 CSV 文件\n",
    "        df = pd.read_csv(file_path)\n",
    "        # 将数据追加到 combined_df\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "# 保存合并后的数据到新的 CSV 文件，使用带有 BOM 的 UTF-8 编码\n",
    "combined_df.to_csv('combined_data.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 定义文件路径\n",
    "path = \"D:\\\\系统默认\\\\桌面\\\\邮政\\\\数据调研\\\\Price\"\n",
    "\n",
    "# 初始化一个空的 DataFrame\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# 遍历所有文件\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(path, file)\n",
    "        # 读取 CSV 文件\n",
    "        df = pd.read_csv(file_path)\n",
    "        # 将数据追加到 combined_df\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "# 保存合并后的数据到新的 CSV 文件，使用带有 BOM 的 UTF-8 编码\n",
    "combined_df.to_csv('combined_data.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_poi_density = np.load('scale_poi_density.npy')\n",
    "scale_poi_diversity = np.load('scale_poi_diversity.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_density_prob = []\n",
    "poi_diversity_prob = []\n",
    "sum_poi_density = np.sum(scale_poi_density)\n",
    "sum_poi_diversity = np.sum(scale_poi_diversity)\n",
    "# 计算概率矩阵\n",
    "for i in range(len(scale_poi_density)):\n",
    "    poi_density_prob.append(scale_poi_density[i] / sum_poi_density)\n",
    "\n",
    "for i in range(len(scale_poi_diversity)):\n",
    "    poi_diversity_prob.append(scale_poi_diversity[i] / sum_poi_diversity)\n",
    "\n",
    "np.save('prob_poi_density.npy', poi_density_prob)\n",
    "np.save('prob_poi_diversity.npy', poi_diversity_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "947961\n"
     ]
    }
   ],
   "source": [
    "# 有多少0\n",
    "print(poi_density_prob.count(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算信息熵\n",
    "def cal_entropy(prob):\n",
    "    entropy = 0\n",
    "    for i in range(len(prob)):\n",
    "        if prob[i] != 0:\n",
    "            entropy -= prob[i] * np.log(prob[i])\n",
    "    # 变为0-1之间\n",
    "    entropy /= np.log(len(prob))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5709951600935983\n"
     ]
    }
   ],
   "source": [
    "hosue_entropy = cal_entropy(house_price_prob)\n",
    "print(hosue_entropy) #0.5709951600935983"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6428892367629705\n",
      "0.6915434317121325\n"
     ]
    }
   ],
   "source": [
    "poi_density_entropy = cal_entropy(poi_density_prob)\n",
    "print(poi_density_entropy) #0.6428892367629705\n",
    "poi_diversity_entropy = cal_entropy(poi_diversity_prob)\n",
    "print(poi_diversity_entropy) #0.6915434317121325"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
